{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7473bc43-6630-444b-ba8a-178faaf68034",
   "metadata": {},
   "source": [
    "# üß™ Anomaly Scoring & Heatmaps\n",
    "\n",
    "In this step, we transform ViT-based features into meaningful **anomaly scores** and **visual heatmaps**.\n",
    "\n",
    "Using the patch-level embeddings from *test images*, we compare them against the **feature bank** built from `train/good` data. This allows us to detect both image-level anomalies and localize defective regions.\n",
    "\n",
    "---\n",
    "\n",
    "### Goals of this notebook:\n",
    "\n",
    "- Compute **image-level anomaly scores** using:\n",
    "  - **KNN distance** (via FAISS)\n",
    "  - Optionally: **Mahalanobis distance**\n",
    "- Generate **pixel-level heatmaps** by projecting patch distances to spatial grids\n",
    "- Upsample and visualize heatmaps as overlays on the original images\n",
    "- Determine an optimal threshold for binary decisions (Youden‚Äôs J or best F1)\n",
    "- Evaluate detection performance using standard metrics (AUROC, PRO, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "This scoring approach works **fully unsupervised**, relying only on normal (`train/good`) examples.\n",
    "\n",
    "By the end of this notebook, you‚Äôll be able to:\n",
    "- Score all test images\n",
    "- Visualize and interpret heatmaps\n",
    "- Quantify anomaly detection performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acaf7e6-7ddc-42e5-8cfb-095fff5ad973",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Features & Metadata\n",
    "\n",
    "In this section, we load the precomputed ViT embeddings and metadata generated during the feature extraction step.\n",
    "\n",
    "Specifically, we will:\n",
    "- Load `.npz` feature files (CLS + patch embeddings) for each category\n",
    "- Load the corresponding `.csv` metadata files\n",
    "- Merge them into a single DataFrame for easy access and filtering\n",
    "\n",
    "This unified structure will allow us to:\n",
    "- Quickly isolate `train/good` features (for scoring)\n",
    "- Select `test` images for evaluation\n",
    "- Link embeddings back to image paths for visualization\n",
    "\n",
    "---\n",
    "\n",
    "Each entry contains:\n",
    "- `cls`: global image embedding (ViT CLS token)\n",
    "- `patches`: local patch embeddings\n",
    "- `patch_hw`: patch grid shape (e.g., 16√ó16)\n",
    "- metadata (path, label, split, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b99c335-c6b1-45da-8ad6-06cb0a6962bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved bottle (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved cable (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved capsule (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved carpet (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved grid (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved hazelnut (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved leather (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved metal_nut (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved pill (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved screw (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved tile (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved toothbrush (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved transistor (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved wood (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved zipper (dino) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\dino\n",
      "‚úÖ Saved bottle (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved cable (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved capsule (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved carpet (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved grid (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved hazelnut (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved leather (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved metal_nut (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved pill (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved screw (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved tile (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved toothbrush (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved transistor (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved wood (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n",
      "‚úÖ Saved zipper (mae) to C:\\Users\\Fredi\\MVTec\\cached_dicts\\mae\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "\n",
    "CFG = {\n",
    "    \"dino\": {\n",
    "        \"FEAT_DIR\": BASE_DIR / \"features_dinov2_b14\",\n",
    "        \"BANK_DIR\": BASE_DIR / \"featurebanks\" / \"dinov2_b14\",\n",
    "        \"FEAT_NPZ_TPL\": \"{cat}_dinov2_vitb14.npz\",\n",
    "        \"BANK_NPZ_TPL\": \"{cat}_bank_dinov2_b14.npz\",\n",
    "    },\n",
    "    \"mae\": {\n",
    "        \"FEAT_DIR\": BASE_DIR / \"features_mae_b16\",\n",
    "        \"BANK_DIR\": BASE_DIR / \"featurebanks\" / \"mae_b16\",\n",
    "        \"FEAT_NPZ_TPL\": \"{cat}_mae_b16.npz\",\n",
    "        \"BANK_NPZ_TPL\": \"{cat}_bank_mae_b16.npz\",\n",
    "    },\n",
    "}\n",
    "\n",
    "def categories_from_feat_dir(feat_dir: Path):\n",
    "    cats = []\n",
    "    for p in feat_dir.glob(\"*_meta.csv\"):\n",
    "        name = p.name\n",
    "        if name.endswith(\"_meta.csv\"):\n",
    "            cats.append(name[:-len(\"_meta.csv\")])\n",
    "    return sorted(set(cats))\n",
    "\n",
    "def load_feature_data(feat_dir: Path, feat_tpl: str, category: str):\n",
    "    feat_file = feat_dir / feat_tpl.format(cat=category)\n",
    "    meta_file = feat_dir / f\"{category}_meta.csv\"\n",
    "    data = np.load(feat_file)\n",
    "    df = pd.read_csv(meta_file)\n",
    "    return {\n",
    "        \"patches\": data[\"patches\"],\n",
    "        \"cls\": data.get(\"cls\"),\n",
    "        \"patch_hw\": tuple(data[\"patch_hw\"]),\n",
    "        \"meta\": df\n",
    "    }\n",
    "\n",
    "def load_feature_bank(bank_dir: Path, bank_tpl: str, category: str):\n",
    "    bank_file = bank_dir / bank_tpl.format(cat=category)\n",
    "    meta_file = bank_dir / f\"{category}_bank_meta.csv\"\n",
    "    data = np.load(bank_file)\n",
    "    df = pd.read_csv(meta_file)\n",
    "    return {\n",
    "        \"patches\": data[\"patches\"],\n",
    "        \"patch_hw\": tuple(data[\"patch_hw\"]),\n",
    "        \"meta\": df\n",
    "    }\n",
    "\n",
    "def save_dicts_to_disk(backbone: str, features_all: dict, banks: dict, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for cat in features_all:\n",
    "        with open(out_dir / f\"{cat}_features.pkl\", \"wb\") as f:\n",
    "            pickle.dump(features_all[cat], f)\n",
    "        with open(out_dir / f\"{cat}_bank.pkl\", \"wb\") as f:\n",
    "            pickle.dump(banks[cat], f)\n",
    "        print(f\"‚úÖ Saved {cat} ({backbone}) to {out_dir}\")\n",
    "\n",
    "def load_backbone(name: str):\n",
    "    cfg = CFG[name]\n",
    "    feat_dir, bank_dir = cfg[\"FEAT_DIR\"], cfg[\"BANK_DIR\"]\n",
    "    feat_tpl, bank_tpl = cfg[\"FEAT_NPZ_TPL\"], cfg[\"BANK_NPZ_TPL\"]\n",
    "\n",
    "    categories = categories_from_feat_dir(feat_dir)\n",
    "    features_all, banks = {}, {}\n",
    "    for cat in categories:\n",
    "        features_all[cat] = load_feature_data(feat_dir, feat_tpl, cat)\n",
    "        banks[cat] = load_feature_bank(bank_dir, bank_tpl, cat)\n",
    "    return categories, features_all, banks\n",
    "\n",
    "# Load and save DINO\n",
    "cats_dino, features_all_dino, banks_dino = load_backbone(\"dino\")\n",
    "save_dicts_to_disk(\"dino\", features_all_dino, banks_dino, BASE_DIR / \"cached_dicts\" / \"dino\")\n",
    "\n",
    "# Load and save MAE\n",
    "cats_mae, features_all_mae, banks_mae = load_backbone(\"mae\")\n",
    "save_dicts_to_disk(\"mae\", features_all_mae, banks_mae, BASE_DIR / \"cached_dicts\" / \"mae\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432845d-b4be-4b4b-8a5d-722013aecfb7",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "\n",
    "After loading, we store the results in two dictionaries.  \n",
    "This design separates **all extracted embeddings** from the **reference banks**,  \n",
    "making evaluation, visualization, and anomaly scoring more convenient.\n",
    "\n",
    "---\n",
    "\n",
    "- **`features_all`**  \n",
    "  Contains the **full embeddings** (train + test) for each category.  \n",
    "  Each entry is a dictionary with:\n",
    "  - `cls`: global image embeddings `[N, D]`\n",
    "  - `patches`: patch embeddings `[N, P, D]`\n",
    "  - `patch_hw`: patch grid dimensions `(H, W)`\n",
    "  - `meta`: metadata DataFrame (paths, labels, splits)\n",
    "\n",
    "  ‚Üí Used when we need to compare across *all images* (e.g., evaluation, visualization).\n",
    "\n",
    "---\n",
    "\n",
    "- **`banks`**  \n",
    "  Contains only the **feature bank**: patch embeddings from `train/good` images.  \n",
    "  Each entry is a dictionary with:\n",
    "  - `patches`: patch embeddings `[N, P, D]`\n",
    "  - `patch_hw`: patch grid dimensions `(H, W)`\n",
    "  - `meta`: metadata DataFrame for good samples\n",
    "\n",
    "  ‚Üí Used as the **reference set** for anomaly scoring: test patches are compared against this bank.\n",
    "\n",
    "\n",
    "These structures allow us to seamlessly switch between global evaluation (`features_all`) and reference-based scoring (`banks`). In the next step, we leverage them to compute image-level anomaly scores and pixel-level heatmaps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee1e6e-d2e7-4788-bcd4-f2ff721a224d",
   "metadata": {},
   "source": [
    "\n",
    "## 2Ô∏è‚É£ Build Search Index / Distribution\n",
    "\n",
    "After extracting features, the next step is to organize the \n",
    "**reference distribution of normal data**. This serves as the \n",
    "foundation for anomaly detection: test samples are compared \n",
    "against this reference to estimate how \"normal\" or \"abnormal\" they are.\n",
    "\n",
    "Two complementary approaches are considered:\n",
    "\n",
    "- **KNN-based feature banks:**  \n",
    "  Patch embeddings from `train/good` images are stored in a \n",
    "  nearest-neighbor index (e.g. FAISS).  \n",
    "  ‚Üí At inference, each test patch is compared to its closest neighbors \n",
    "  in this bank.\n",
    "\n",
    "- **Mahalanobis distribution:**  \n",
    "  A parametric approach where we compute the mean vector and covariance \n",
    "  matrix of `train/good` patches per category.  \n",
    "  ‚Üí Anomaly scores are then derived from the multivariate distance \n",
    "  between test patches and this distribution.\n",
    "\n",
    "This step transforms the raw feature embeddings into \n",
    "a **searchable structure** (index or distribution) that enables \n",
    "efficient and principled anomaly scoring in the following step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843ee6b-7ed2-45ec-ab27-3189b14825ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mvtec)",
   "language": "python",
   "name": "mvtec-vit-anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
